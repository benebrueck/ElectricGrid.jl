{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa1010c",
   "metadata": {},
   "source": [
    "# Package Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e01153",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "937a199a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: 1 sourceType not defined! set to ideal!\n",
      "INFO: Normalization done based in defined parameterlimits\n",
      "WARNING: 9 Current limits set to 1000 A - please define in nc.parameters -> source -> i_limit!\n",
      "WARNING: 3 Voltage limits set to 1500 V - please define in nc.parameters -> source -> v_limit!\n"
     ]
    }
   ],
   "source": [
    "setup1 = create_setup(num_sources = 2, num_loads = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e881abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeConstructor(2, 2, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 2, 6, 10, 0, 3, [0.0 0.0 1.0; 0.0 0.0 2.0; -1.0 -2.0 0.0], Dict{Any, Any}(\"source\" => Any[Dict{Any, Any}(\"L1\" => 0.0004936648364348163, \"C\" => 0.00011658116457610016, \"fltr\" => \"LC\", \"pwr\" => 100000.0, \"source_type\" => \"ideal\", \"R_C\" => 0.0032642726081308043, \"i_limit\" => 244.7350017234564, \"v_rip\" => 0.014057658423141968, \"v_δ_set\" => 0.0, \"vdc\" => 800…), Dict{Any, Any}(\"L1\" => 0.0004936648364348163, \"C\" => 0.00011658116457610016, \"fltr\" => \"LC\", \"pwr\" => 100000.0, \"source_type\" => \"ideal\", \"R_C\" => 0.0032642726081308043, \"i_limit\" => 244.7350017234564, \"v_rip\" => 0.014057658423141968, \"v_δ_set\" => 0.0, \"vdc\" => 800…)], \"load\" => Any[Dict{Any, Any}(\"L\" => 0.012628944734341892, \"R\" => 5.289999999999998, \"impedance\" => \"RL\")], \"grid\" => Dict{String, Real}(\"fs\" => 10000.0, \"phase\" => 3, \"v_rms\" => 230), \"cable\" => Any[Dict{Any, Any}(\"Cb\" => 4.0e-7, \"Lb\" => 0.000264, \"Rb\" => 0.722, \"C\" => 1.0e-6, \"len\" => 9.47969496662979, \"L\" => 0.000625, \"R\" => 0.52), Dict{Any, Any}(\"Cb\" => 4.0e-7, \"Lb\" => 0.000264, \"Rb\" => 0.722, \"C\" => 1.0e-6, \"len\" => 9.47969496662979, \"L\" => 0.000625, \"R\" => 0.52)]), 0.1, 0.8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup1.env.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a477555",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: Column episode is already present in the data frame which is not allowed when `makeunique=true`",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Column episode is already present in the data frame which is not allowed when `makeunique=true`\n",
      "\n",
      "Stacktrace:\n",
      " [1] insertcols!(df::DataFrames.DataFrame, col::Int64, name_cols::Pair{Symbol, Int64}; after::Bool, makeunique::Bool, copycols::Bool)\n",
      "   @ DataFrames C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\dataframe\\dataframe.jl:872\n",
      " [2] #insertcols!#202\n",
      "   @ C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\dataframe\\dataframe.jl:967 [inlined]\n",
      " [3] insertcols!(df::DataFrames.DataFrame, name_cols::Pair{Symbol, Int64})\n",
      "   @ DataFrames C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\dataframe\\dataframe.jl:967\n",
      " [4] (::DataHook)(#unused#::ReinforcementLearningCore.PreActStage, agent::ReinforcementLearningCore.Agent{ReinforcementLearningZoo.DDPGPolicy{ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.RandomPolicy{IntervalSets.ClosedInterval{Float64}, StableRNGs.LehmerRNG}, StableRNGs.LehmerRNG}, ReinforcementLearningCore.CircularArraySARTTrajectory{NamedTuple{(:state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}}}}}, env::SimEnv, action::Vector{Float64})\n",
      "   @ Dare c:\\Users\\SeptimusBoshoff\\OneDrive - Power System Dynamics\\Documents\\Doctor of Philosophy\\Paderborn Projects\\DARE\\dare\\src\\data_hook.jl:165\n",
      " [5] _run(policy::ReinforcementLearningCore.Agent{ReinforcementLearningZoo.DDPGPolicy{ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.RandomPolicy{IntervalSets.ClosedInterval{Float64}, StableRNGs.LehmerRNG}, StableRNGs.LehmerRNG}, ReinforcementLearningCore.CircularArraySARTTrajectory{NamedTuple{(:state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}}}}}, env::SimEnv, stop_condition::ReinforcementLearningCore.StopAfterEpisode{ProgressMeter.Progress}, hook::DataHook)\n",
      "   @ ReinforcementLearningCore C:\\Users\\SeptimusBoshoff\\.julia\\packages\\ReinforcementLearningCore\\yeRLW\\src\\core\\run.jl:30\n",
      " [6] run(policy::ReinforcementLearningCore.Agent{ReinforcementLearningZoo.DDPGPolicy{ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(tanh), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.NeuralNetworkApproximator{Flux.Chain{Tuple{Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(NNlib.relu), Matrix{Float32}, Vector{Float32}}, Flux.Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}, Flux.Optimise.ADAM}, ReinforcementLearningCore.RandomPolicy{IntervalSets.ClosedInterval{Float64}, StableRNGs.LehmerRNG}, StableRNGs.LehmerRNG}, ReinforcementLearningCore.CircularArraySARTTrajectory{NamedTuple{(:state, :action, :reward, :terminal), Tuple{CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularArrayBuffer{Float32, 2, Matrix{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Float32, Vector{Float32}}, CircularArrayBuffers.CircularVectorBuffer{Bool, Vector{Bool}}}}}}, env::SimEnv, stop_condition::ReinforcementLearningCore.StopAfterEpisode{ProgressMeter.Progress}, hook::DataHook)\n",
      "   @ ReinforcementLearningCore C:\\Users\\SeptimusBoshoff\\.julia\\packages\\ReinforcementLearningCore\\yeRLW\\src\\core\\run.jl:10\n",
      " [7] run(dare_setup::dare_setup, no_episodes::Int64)\n",
      "   @ Dare c:\\Users\\SeptimusBoshoff\\OneDrive - Power System Dynamics\\Documents\\Doctor of Philosophy\\Paderborn Projects\\DARE\\dare\\src\\Dare_Wrapper.jl:138\n",
      " [8] top-level scope\n",
      "   @ c:\\Users\\SeptimusBoshoff\\OneDrive - Power System Dynamics\\Documents\\Doctor of Philosophy\\Paderborn Projects\\DARE\\dare\\examples\\Package_DEMO.ipynb:1"
     ]
    }
   ],
   "source": [
    "Dare.run(setup1, 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d7dabcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "ArgumentError: column name :episode not found in the data frame since it has no columns",
     "output_type": "error",
     "traceback": [
      "ArgumentError: column name :episode not found in the data frame since it has no columns\n",
      "\n",
      "Stacktrace:\n",
      " [1] lookupname\n",
      "   @ C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\other\\index.jl:389 [inlined]\n",
      " [2] getindex\n",
      "   @ C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\other\\index.jl:401 [inlined]\n",
      " [3] getindex(df::DataFrames.DataFrame, #unused#::typeof(!), col_ind::Symbol)\n",
      "   @ DataFrames C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\dataframe\\dataframe.jl:525\n",
      " [4] getproperty(df::DataFrames.DataFrame, col_ind::Symbol)\n",
      "   @ DataFrames C:\\Users\\SeptimusBoshoff\\.julia\\packages\\DataFrames\\zqFGs\\src\\abstractdataframe\\abstractdataframe.jl:378\n",
      " [5] plot_hook_results(; hook::DataHook, states_to_plot::Nothing, actions_to_plot::Nothing, plot_reward::Bool, plot_reference::Bool, episode::Int64, vdc_to_plot::Vector{Any}, vdq_to_plot::Vector{Any}, idq_to_plot::Vector{Any}, pq_to_plot::Vector{Any}, vrms_to_plot::Vector{Any}, irms_to_plot::Vector{Any})\n",
      "   @ Dare c:\\Users\\SeptimusBoshoff\\OneDrive - Power System Dynamics\\Documents\\Doctor of Philosophy\\Paderborn Projects\\DARE\\dare\\src\\plotting.jl:148\n",
      " [6] top-level scope\n",
      "   @ c:\\Users\\SeptimusBoshoff\\OneDrive - Power System Dynamics\\Documents\\Doctor of Philosophy\\Paderborn Projects\\DARE\\dare\\examples\\Package_DEMO.ipynb:1"
     ]
    }
   ],
   "source": [
    "plot_hook_results(; hook = setup1.hook, plot_reward = false, plot_reference = false, episode = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
