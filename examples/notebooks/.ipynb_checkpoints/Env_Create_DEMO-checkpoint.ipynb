{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aa1010c",
   "metadata": {},
   "source": [
    "# SimEnv Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d57658",
   "metadata": {},
   "source": [
    "This notebook is intended to show the functionality of the SimEnv which creates an environment for simulation of power-electronic driven microgrids with ad-hoc data generation.\n",
    "It can be used to to train and test reinforcement learing agents (e.g., from \n",
    "https://juliareinforcementlearning.org/).\n",
    "These agents can learn to handle different control tasks and can be compared to classical control approaches.\n",
    "\n",
    "The dynmaic bahaviour of the envorinment is simulated using linear state-space systems.\n",
    "It interacts step-wise with the agent/controller like shown in the figure below.\n",
    "Based on the input/action `u` at timestep `k` the state `x` is calculated.\n",
    "\n",
    "  \n",
    "![](figures/RL_env.png \"\")\n",
    "\n",
    "\n",
    "To use the Dare tool the Dare package has to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e01153",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabf77a",
   "metadata": {},
   "source": [
    "## Simplest initialisation\n",
    "The easiest way to initialize an environment is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937a199a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# SimEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                                            Value |\n",
       "|:----------------- | ------------------------------------------------:|\n",
       "| NumAgentStyle     |          ReinforcementLearningBase.SingleAgent() |\n",
       "| DynamicStyle      |           ReinforcementLearningBase.Sequential() |\n",
       "| InformationStyle  | ReinforcementLearningBase.ImperfectInformation() |\n",
       "| ChanceStyle       |           ReinforcementLearningBase.Stochastic() |\n",
       "| RewardStyle       |           ReinforcementLearningBase.StepReward() |\n",
       "| UtilityStyle      |           ReinforcementLearningBase.GeneralSum() |\n",
       "| ActionStyle       |     ReinforcementLearningBase.MinimalActionSet() |\n",
       "| StateStyle        |     ReinforcementLearningBase.Observation{Any}() |\n",
       "| DefaultStateStyle |     ReinforcementLearningBase.Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`ReinforcementLearningBase.Space{Vector{IntervalSets.ClosedInterval{Float64}}}(IntervalSets.ClosedInterval{Float64}[-1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`ReinforcementLearningBase.Space{Vector{IntervalSets.ClosedInterval{Float64}}}(IntervalSets.ClosedInterval{Float64}[-1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0])`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "```\n"
      ],
      "text/plain": [
       "# SimEnv\n",
       "\n",
       "## Traits\n",
       "\n",
       "| Trait Type        |                                            Value |\n",
       "|:----------------- | ------------------------------------------------:|\n",
       "| NumAgentStyle     |          ReinforcementLearningBase.SingleAgent() |\n",
       "| DynamicStyle      |           ReinforcementLearningBase.Sequential() |\n",
       "| InformationStyle  | ReinforcementLearningBase.ImperfectInformation() |\n",
       "| ChanceStyle       |           ReinforcementLearningBase.Stochastic() |\n",
       "| RewardStyle       |           ReinforcementLearningBase.StepReward() |\n",
       "| UtilityStyle      |           ReinforcementLearningBase.GeneralSum() |\n",
       "| ActionStyle       |     ReinforcementLearningBase.MinimalActionSet() |\n",
       "| StateStyle        |     ReinforcementLearningBase.Observation{Any}() |\n",
       "| DefaultStateStyle |     ReinforcementLearningBase.Observation{Any}() |\n",
       "\n",
       "## Is Environment Terminated?\n",
       "\n",
       "No\n",
       "\n",
       "## State Space\n",
       "\n",
       "`ReinforcementLearningBase.Space{Vector{IntervalSets.ClosedInterval{Float64}}}(IntervalSets.ClosedInterval{Float64}[-1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0])`\n",
       "\n",
       "## Action Space\n",
       "\n",
       "`ReinforcementLearningBase.Space{Vector{IntervalSets.ClosedInterval{Float64}}}(IntervalSets.ClosedInterval{Float64}[-1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0])`\n",
       "\n",
       "## Current State\n",
       "\n",
       "```\n",
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
       "```\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = SimEnv(num_sources = 2, num_loads = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ae85f",
   "metadata": {},
   "source": [
    "This creates an environment consisting of an electrical power grid with two sources `num_sources = 2` (which could be for example an inverter fed by a PV plant or a wind turbine or battery) - supplying one load `num_sources = 1`.\n",
    "An easy exemplary example is shown in the figure below, where a load (an electric car to be charged) is supplied by 2 sources (inverters, fed PV plant and wind turbine) via two transmission lines.\n",
    "\n",
    "![](figures/ExampleGrid1.png \"\")\n",
    "\n",
    "For better visuablilty an exemplary shaded electircal circut in the background is displayed as single phase diagram.\n",
    "(By default a three-phase four wire system is created).\n",
    "If it is not defined during the initialization of the env, all parameters (connections between the different sources and loads, parameters of the electric components,...) are drawn randomly, while a few are set to fixed value per default.\n",
    "One of the latter would be for example the stepsize `ts`. After the initialization a step-wise interaction with the environment is possible. \n",
    "As can be seen in the first picture, an action can be selected and the env can be executed with it. \n",
    "Based on that action `u_k` and the internal state-space system (defined depending on the electric components - for more information about the odernary differential equation,... see NodeConstructor_DEMO.ipynb) the system is evolved for one timestep and the new states `x_k+1` of the system are calulated.\n",
    "\n",
    "### States and actions\n",
    "\n",
    "First, the current states of the environment are checked:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fdd5b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36-element Vector{Float64}:\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b507ff2",
   "metadata": {},
   "source": [
    "If the state is not zero, but should be in the beginning, the reset method can be used which sets the state to the internally defined `x0` (which consists of zeros per default).\n",
    "If we do not want to not start from zero, we could set `x0` in the initialisation of the env:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed8f10b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36-element Vector{Float64}:\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " ⋮\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1\n",
       " 0.1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using ReinforcementLearning\n",
    "env.x0 = 0.1 * ones(length(env.state_space))\n",
    "reset!(env)\n",
    "env.state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f346cc",
   "metadata": {},
   "source": [
    "To interact with the env, it has to be figured out how many actions are needed. Therefore the length of the action space can be checked:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c74e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_a = length(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4155c448",
   "metadata": {},
   "source": [
    "The six action requested by the environment belong to the 2 sources. Since per default the env produces a three-phase system we need one action per phase per source -> 6 actions.\n",
    "To excite the env by an action the following command can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5393930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-element Vector{Float64}:\n",
       " -0.1098765413217325\n",
       " -0.004741537135149022\n",
       " -0.071616657870071\n",
       " -0.1503420876058934\n",
       "  0.0782343390093986\n",
       " -0.06189823161512922\n",
       " -0.04568223294113191\n",
       " -0.0029234769102493914\n",
       "  0.031114891850429774\n",
       "  0.10587786414573112\n",
       "  ⋮\n",
       " -0.004741537135149022\n",
       " -0.071616657870071\n",
       " -0.1503420876058934\n",
       "  0.0782343390093986\n",
       " -0.06189823161512922\n",
       " -0.04568223294113191\n",
       " -0.0029234769102494057\n",
       "  0.031114891850429757\n",
       "  0.10587786414573112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env([0.2, 0.2, 0.2, 0.3, 0.3, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff5143",
   "metadata": {},
   "source": [
    "Here, the first source got an action of `0.2` to all three phases, while the second source got an action of `0.3` to all three phases.\n",
    "As can be seen, the states have changed from 0.1 to different values.\n",
    "To get a little bit more intuition about the different states, the state_ids can be investigated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddc6fbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-element Vector{String}:\n",
       " \"source1_i_L1_a\"\n",
       " \"source1_v_C_filt_a\"\n",
       " \"source1_v_C_cables_a\"\n",
       " \"source2_i_L1_a\"\n",
       " \"source2_v_C_cables_a\"\n",
       " \"cable1_i_L_a\"\n",
       " \"cable2_i_L_a\"\n",
       " \"cable3_i_L_a\"\n",
       " \"load1_v_C_total_a\"\n",
       " \"load1_i_L_a\"\n",
       " ⋮\n",
       " \"source1_v_C_filt_c\"\n",
       " \"source1_v_C_cables_c\"\n",
       " \"source2_i_L1_c\"\n",
       " \"source2_v_C_cables_c\"\n",
       " \"cable1_i_L_c\"\n",
       " \"cable2_i_L_c\"\n",
       " \"cable3_i_L_c\"\n",
       " \"load1_v_C_total_c\"\n",
       " \"load1_i_L_c\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.state_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15505673",
   "metadata": {},
   "source": [
    "The labels define to which source the state belongs and what it is about. \n",
    "For example the first state is called `\"source1_i_L1_a\"`. That tells, it belongs to the first source (in the picture above the PV plant) and represents the current `i` through the incductor `L1` of phase `a`.\n",
    "For example, this information can be used to control the current through the filter inductance (or to learn this control task).\n",
    "\n",
    "An example for a single phase 3 Bus grid consisting of 2 sources (LC and LCL filter), 3 cables and 1 RLC load is shown in the following figure highligthing some of the defineable parameters and states.\n",
    "This example only shows the equivalent electrical circuit diagramm but is similar to the example with the PV, windturbine and electric car. The only difference here is that the two sources are connected, too. \n",
    "\n",
    "![](figures/ExampleGrid3.png \"\")\n",
    "\n",
    "A few states are labeled in red, while a few parameters defined in the parameter dict are marked in green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0419b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Space{Vector{IntervalSets.ClosedInterval{Float64}}}(IntervalSets.ClosedInterval{Float64}[-1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0  …  -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0, -1.0..1.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.state_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7973f0",
   "metadata": {},
   "source": [
    "Since the state space of the env tells, that it ranges from -1.0..1.0, the current `\"source1_i_L1_a\"` through the filter inductor in the example is normalized by the maximal current allowed to flow through the inductor.\n",
    "If this parameter is not defined it it set per default based on the filter layout happening in the env.\n",
    "\n",
    "\n",
    "\n",
    "All (technical) parameters needed for the simulation are defined in the parameter dict (for more detailed information see below and NodeConstructor_DEMO.ipynb).\n",
    "It can be investigated by:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b375692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 4 entries:\n",
       "  \"source\" => Any[Dict{Any, Any}(\"L1\"=>0.00170766, \"C\"=>3.08246e-5, \"mode\"=>\"Sy…\n",
       "  \"grid\"   => Dict{Any, Any}(\"f_grid\"=>50, \"Δfmax\"=>0.005, \"fs\"=>10000.0, \"proc…\n",
       "  \"load\"   => Any[Dict{Any, Any}(\"Z\"=>8.64561-6.22694im, \"C\"=>0.000255711, \"L\"=…\n",
       "  \"cable\"  => Any[Dict{Any, Any}(\"Cb\"=>4.0e-7, \"Lb\"=>0.000264, \"Rb\"=>0.722, \"C\"…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e36955",
   "metadata": {},
   "source": [
    "The limit of the filter inductor current can be found using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb4e6731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.15602558819927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"source\"][1][\"i_limit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1d5e0",
   "metadata": {},
   "source": [
    "Which returns the current limit (belonging to the inductor) of source one.\n",
    "The voltage limit for normalization is depending on the filter capacitor and calulated - if not defined - based on the capacitance.\n",
    "The same concept holds for the cables and loads (parametrization can be found in the parameter dict, too).\n",
    "\n",
    "Since the action space is defined in a range -1.0..1.0, the actions are \"normalized\" by the DC-link voltage of the specific source. \n",
    "In the simulation the chosen action is multiplied by half of the DC-link voltage (and can be interpreted as modulation index in an electrical engineering context).\n",
    "The DC-link voltage can be found in (or set via) the parameter dict, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b4c3fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"source\"][1][\"vdc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e034f1",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "The wanted setting of the simulation can be adjusted using the parameter dict. \n",
    "The most important parts will be investigated in the following.\n",
    "Like already shown above the parameter dict splits up into different parts describing different sections of the grid: gird, source, load, cable.\n",
    "\n",
    "Now the most important parts of the parameter dict are investigated in more detail.\n",
    "\n",
    "#### Grid\n",
    "Defines the basic setting of the whole electrical power grid. The moste important parameters are:\n",
    "\n",
    "- `\"f_grid\"`: grid frequency (frequency of the sine wave) (default: 50 Hz)\n",
    "- `\"phases\"`: number of phases in the electric power grid (exclusive neutral). (default: 3)\n",
    "- `\"fs\"`: sample frequency of the simulation. Every step the environment if simulated `1/fs` s forward (default: 10 kHz)\n",
    "- `\"v_rms\"`: root mean square value of the basic grid voltage (default: 230 V)\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825fab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 9 entries:\n",
       "  \"f_grid\"        => 50\n",
       "  \"Δfmax\"         => 0.005\n",
       "  \"fs\"            => 10000.0\n",
       "  \"process_start\" => 0.04\n",
       "  \"phase\"         => 3\n",
       "  \"ramp_end\"      => 0.04\n",
       "  \"ΔEmax\"         => 0.05\n",
       "  \"pwr\"           => 85000.0\n",
       "  \"v_rms\"         => 230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"grid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37031fa",
   "metadata": {},
   "source": [
    "#### Source\n",
    "A selection of the most important parameters that can be defined and configured via the parameter dict is given in the following:\n",
    "\n",
    "- `\"pwr\"`: maximum aparent power of the source (default: random)\n",
    "- `\"source_type\"`: type of the electric component sitting on the DC side, e.g. ideal (constant `vdc`), PV,... (default: ideal)\n",
    "- `\"control_type\"`: defines whether the source is classically controlled or RL controlled (default = \"classic\")\n",
    "- `\"mode\"`: allows to specify which control mode the source (default = \"Droop\", and classic control_type) (for more information, see Classic_Controllers_Notebook.iypnb)\n",
    "- `\"vdc\"`: DC-link voltage, fixed if `\"source_type\"` is ideal (drawn random $U$[690, 800] V), otherwise drawn from function\n",
    "- `\"fltr\"`: Filter type [L, LC, LCL] (default: random)\n",
    "- `\"i_limit\"`: maximal allowed current flowing through the inductor(s) (default: calculated based on filter parameters)\n",
    "- `\"v_limit\"`: maximal allowed voltage across the capacitor (default: calculated based on filter parameters).\n",
    "- ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcfee150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 28 entries:\n",
       "  \"L1\"           => 0.00170766\n",
       "  \"C\"            => 3.08246e-5\n",
       "  \"mode\"         => \"Synchronverter\"\n",
       "  \"fltr\"         => \"LC\"\n",
       "  \"pwr\"          => 40000.0\n",
       "  \"source_type\"  => \"ideal\"\n",
       "  \"R_C\"          => 2.48102\n",
       "  \"std_asy\"      => 10000.0\n",
       "  \"σ\"            => 0.0\n",
       "  \"i_limit\"      => 139.156\n",
       "  \"v_rip\"        => 0.01537\n",
       "  \"v_δ_set\"      => 0.0\n",
       "  \"vdc\"          => 800\n",
       "  \"τv\"           => 0.002\n",
       "  \"k\"            => 0\n",
       "  \"control_type\" => \"classic\"\n",
       "  \"v_pu_set\"     => 1.0\n",
       "  \"τf\"           => 0.002\n",
       "  \"i_rip\"        => 0.15\n",
       "  ⋮              => ⋮"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"source\"][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d2ec5",
   "metadata": {},
   "source": [
    "#### Load\n",
    "Defines passive loads which can be pluged/connected to the grid. All combinations of the passive components of a resistor, inductor and capacitor (\"impedance\") can be chosen:\n",
    "\n",
    "- `\"impedance\"`: type/circuit of the load (can be something out of [RLC, RL, RC, LC, R, L, C]). Components will be connected in parallel (default: random)\n",
    "- `\"pwr\"`: apparant power of drawn from the load assuming fixed vrms grid voltage and frequency and the number of phases (see parameters of \"grid\")\n",
    "- `\"pf\"`: power factor resulting from chosen parameters\n",
    "- `\"Z\"`: impedance resulting from chosen parameters\n",
    "- `\"R\"`: load resistance\n",
    "- ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ab14142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Any}:\n",
       " Dict{Any, Any}(\"Z\" => 8.645614985778817 - 6.226943873467353im, \"C\" => 0.00025571060022957864, \"L\" => 0.12491902487968094, \"R\" => 13.130527865555832, \"pwr\" => 14894.91016754301, \"pf\" => -0.811440822661242, \"impedance\" => \"RLC\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"load\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8675c0d9",
   "metadata": {},
   "source": [
    "#### Cable\n",
    "The cables are modelled using PI-models like shown in the figure above.\n",
    "If no parameters are defined they are chosen based on the power flowing through the cable.\n",
    "\n",
    "\n",
    "- `\"len\"`: length of the cable (default: random [1m, 1km])\n",
    "- `\"i_limit\"`: mamimal allowed current flowing through the inductor (default: calculated based on power flow and inductance)\n",
    "- `\"v_limit\"`: since the capacitance it added to the one (if) defined in the source, the limit for the voltage can be found in the source parameter dict\n",
    "- `\"Cb\"`: cable capacity coatings (default: 0.4 µF)\n",
    "- `\"Lb\"`: cable operating inductor (default: 0.264 mH)\n",
    "- `\"Rb\"`: cable AC resistor (default: 0.722 Ohm)\n",
    "- `\"C\"`: cable capacity (default: `\"len\"`*`\"Cb\"`)\n",
    "- `\"L\"`: cable inductance (default: `\"len\"`*`\"Lb\"`)\n",
    "- `\"R\"`: cable resistance (default: `\"len\"`*`\"Rb\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "026200f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Any}:\n",
       " Dict{Any, Any}(\"Cb\" => 4.0e-7, \"Lb\" => 0.000264, \"Rb\" => 0.722, \"C\" => 0.0004, \"i_limit\" => 1.0e13, \"len\" => 1.0, \"L\" => 0.00025, \"R\" => 0.208)\n",
       " Dict{Any, Any}(\"Cb\" => 4.0e-7, \"Lb\" => 0.000264, \"Rb\" => 0.722, \"C\" => 0.0004, \"i_limit\" => 1.0e13, \"len\" => 1.0, \"L\" => 0.00025, \"R\" => 0.208)\n",
       " Dict{Any, Any}(\"Cb\" => 4.0e-7, \"Lb\" => 0.000264, \"Rb\" => 0.722, \"C\" => 0.0004, \"i_limit\" => 1.0e13, \"len\" => 1.0, \"L\" => 0.00025, \"R\" => 0.208)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.nc.parameters[\"cable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85446a",
   "metadata": {},
   "source": [
    "For all information about the parameters which can be defined investigate the parameter dict itself or have a look into the documentation (`LINK`).\n",
    "\n",
    "The next step would be to interact with the env to run an experiment.\n",
    "To learn how to do this, see the `Env_Interaction_DEMO.ipynb`."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
