{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4c866f",
   "metadata": {},
   "source": [
    "## Using CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "346b3727",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DrWatson\n",
    "@quickactivate \"MicroGridSimWithRL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7655cb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "using Test\n",
    "using BenchmarkTools\n",
    "using Flux\n",
    "using ReinforcementLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f807c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N =10\n",
    "x_d = CUDA.fill(1.0f0, N) # Float32\n",
    "y_d = CUDA.fill(2.0f0, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57217413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0\n",
       " 3.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_d .+= x_d\n",
    "y_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7caf590e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\u001b[1mTest Passed\u001b[22m\u001b[39m\n",
       "  Expression: all(y_d .== 3.0f0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@test all(y_d .== 3.0f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1699f65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element CuArray{Float32, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function broadcast_add!(x, y)\n",
    "        CUDA.@sync y += x\n",
    "    nothing\n",
    "end\n",
    "\n",
    "fill!(y_d, 2)\n",
    "x_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b742c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  78.300 μs (16 allocations: 752 bytes)\n"
     ]
    }
   ],
   "source": [
    "@btime broadcast_add!($x_d, $y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c004545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(gpu_add1!), Tuple{CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1}}}(gpu_add1!, CuFunction(Ptr{Nothing} @0x0000000091e5aeb0, CuModule(Ptr{Nothing} @0x000000000b588ab0, CuContext(0x00000000918f14e0, instance d705e3f736760a58))), CUDA.KernelState(Ptr{Nothing} @0x0000000304000000))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function gpu_add1!(x, y)\n",
    "    for i = 1:length(x)\n",
    "        @inbounds y[i] += x[i]\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "fill!(y_d, 2)\n",
    "\n",
    "@cuda gpu_add1!(x_d, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71629580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  75.900 μs (5 allocations: 304 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(gpu_add1!), Tuple{CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1}}}(gpu_add1!, CuFunction(Ptr{Nothing} @0x0000000091e5aeb0, CuModule(Ptr{Nothing} @0x000000000b588ab0, CuContext(0x00000000918f14e0, instance d705e3f736760a58))), CUDA.KernelState(Ptr{Nothing} @0x0000000304000000))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function benc_gpu1!(x, y)\n",
    "    CUDA.@sync begin\n",
    "        @cuda gpu_add1!(x, y)\n",
    "    end\n",
    "end\n",
    "\n",
    "@btime benc_gpu1!($x_d, $y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbd7c8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Calling CUDA.@profile only informs an external profiler to start.\n",
      "│ The user is responsible for launching Julia under a CUDA profiler.\n",
      "│ \n",
      "│ It is recommended to use Nsight Systems, which supports interactive profiling:\n",
      "│ $ nsys launch julia\n",
      "└ @ CUDA.Profile C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\profile.jl:82\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(gpu_add1!), Tuple{CuDeviceVector{Float32, 1}, CuDeviceVector{Float32, 1}}}(gpu_add1!, CuFunction(Ptr{Nothing} @0x0000000091e5aeb0, CuModule(Ptr{Nothing} @0x000000000b588ab0, CuContext(0x00000000918f14e0, instance d705e3f736760a58))), CUDA.KernelState(Ptr{Nothing} @0x0000000304000000))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CUDA.@profile benc_gpu1!(x_d, y_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12711560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       " 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = CuArray([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d09ebb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Scalar indexing is disallowed.\nInvocation of setindex! resulted in scalar indexing of a GPU array.\nThis is typically caused by calling an iterating implementation of a method.\nSuch implementations *do not* execute on the GPU, but very slowly on the CPU,\nand therefore are only permitted from the REPL for prototyping purposes.\nIf you did intend to index this array, annotate the caller with @allowscalar.",
     "output_type": "error",
     "traceback": [
      "Scalar indexing is disallowed.\n",
      "Invocation of setindex! resulted in scalar indexing of a GPU array.\n",
      "This is typically caused by calling an iterating implementation of a method.\n",
      "Such implementations *do not* execute on the GPU, but very slowly on the CPU,\n",
      "and therefore are only permitted from the REPL for prototyping purposes.\n",
      "If you did intend to index this array, annotate the caller with @allowscalar.\n",
      "\n",
      "Stacktrace:\n",
      " [1] error(s::String)\n",
      "   @ Base .\\error.jl:33\n",
      " [2] assertscalar(op::String)\n",
      "   @ GPUArraysCore C:\\Users\\vikas\\.julia\\packages\\GPUArraysCore\\lojQM\\src\\GPUArraysCore.jl:87\n",
      " [3] setindex!\n",
      "   @ C:\\Users\\vikas\\.julia\\packages\\GPUArrays\\fqD8z\\src\\host\\indexing.jl:17 [inlined]\n",
      " [4] _append!(a::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}, #unused#::Base.HasLength, iter::Tuple{Int64})\n",
      "   @ Base .\\array.jl:1060\n",
      " [5] append!\n",
      "   @ .\\array.jl:1050 [inlined]\n",
      " [6] push!(a::CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}, iter::Int64)\n",
      "   @ Base .\\array.jl:1051\n",
      " [7] top-level scope\n",
      "   @ t:\\DARE\\Julia\\DARE\\dare\\pre_investigations\\julia\\notebooks\\Experiments with CUDA.ipynb:2"
     ]
    }
   ],
   "source": [
    "for i = 1:200\n",
    "    push!(A, i)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bea912db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       "                   1\n",
       " 4629700418014806016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7534d941",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: sample not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: sample not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[30]:1",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "sample(A, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f4d701f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchSampler{(:state, :action, :reward, :terminal, :next_state)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchSampler{SARTS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69492fda",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: p not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: p not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[33]:1",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": [
    "inds, batch = sample(p.rng, traj, BatchSampler{SARTS}(p.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "facdb6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{VersionNumber}:\n",
       " v\"6.1.0\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [CUDA.capability(dev) for dev in CUDA.devices()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a1915ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CuDevice(0): NVIDIA GeForce MX150"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDA.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b07b410f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add(x, y)\n",
    "    x+y\n",
    "end\n",
    "\n",
    "add(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c398671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing"
     ]
    }
   ],
   "source": [
    "function Flux.gpu(add)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "328f7050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91386cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= cu(1)\n",
    "y = cu(2)\n",
    "add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec50811a",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: type not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: type not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[45]:1",
      " [2] eval",
      "   @ .\\boot.jl:373 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1196"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56261134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  21.486 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaf5582",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @btime not defined\nin expression starting at t:\\DARE\\Julia\\DARE\\dare\\pre_investigations\\julia\\notebooks\\Experiments with CUDA.ipynb:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @btime not defined\n",
      "in expression starting at t:\\DARE\\Julia\\DARE\\dare\\pre_investigations\\julia\\notebooks\\Experiments with CUDA.ipynb:1\n"
     ]
    }
   ],
   "source": [
    "@btime Flux.gpu(add($x,$y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb694368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "# 1 method for generic function <b>add</b>:<ul><li> add(x, y) in Main at In[36]:1</li> </ul>"
      ],
      "text/plain": [
       "# 1 method for generic function \"add\":\n",
       "[1] add(x, y) in Main at In[36]:1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69c9c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA toolkit 11.7, artifact installation\n",
      "Unknown NVIDIA driver, for CUDA 11.7\n",
      "CUDA driver 11.7\n",
      "\n",
      "Libraries: \n",
      "- CUBLAS: 11.10.1\n",
      "- CURAND: 10.2.10\n",
      "- CUFFT: 10.7.1\n",
      "- CUSOLVER: 11.3.5\n",
      "- CUSPARSE: 11.7.3\n",
      "- CUPTI: 17.0.0\n",
      "- NVML: missing\n",
      "- CUDNN: 8.30.2 (for CUDA 11.5.0)\n",
      "- CUTENSOR: 1.4.0 (for CUDA 11.5.0)\n",
      "\n",
      "Toolchain:\n",
      "- Julia: 1.7.2\n",
      "- LLVM: 12.0.1\n",
      "- PTX ISA support: 3.2, 4.0, 4.1, 4.2, 4.3, 5.0, 6.0, 6.1, 6.3, 6.4, 6.5, 7.0\n",
      "- Device capability support: sm_35, sm_37, sm_50, sm_52, sm_53, sm_60, sm_61, sm_62, sm_70, sm_72, sm_75, sm_80\n",
      "\n",
      "Environment:\n",
      "- JULIA_CUDA_NSYS: C:\\Program Files\\NVIDIA Corporation\\Nsight Systems 2022.1.3\\target-windows-x64\\nsys.exe\n",
      "\n",
      "1 device:\n",
      "  0: NVIDIA GeForce MX150 (sm_61, 1.623 GiB / 2.000 GiB available)\n"
     ]
    }
   ],
   "source": [
    "CUDA.versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39b088fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
     ]
    }
   ],
   "source": [
    "# Kernel Programming\n",
    "function vadd(c, a, b)\n",
    "    i = threadIdx().x\n",
    "    c[i] = a[i] + b[i]\n",
    "    return\n",
    "end\n",
    "\n",
    "a = CuArray(1:10)\n",
    "b = CuArray(1:10)\n",
    "c = similar(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e239784c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(vadd), Tuple{CuDeviceVector{Int64, 1}, CuDeviceVector{Int64, 1}, CuDeviceVector{Int64, 1}}}(vadd, CuFunction(Ptr{Nothing} @0x0000000091e5eb10, CuModule(Ptr{Nothing} @0x00000000a017eaa0, CuContext(0x00000000918f14e0, instance d705e3f736760a58))), CUDA.KernelState(Ptr{Nothing} @0x0000000304000000))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@cuda threads=length(a) vadd(c, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef7633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98874a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c8bd791",
   "metadata": {},
   "outputs": [
    {
     "ename": "CuError",
     "evalue": "CUDA error: invalid argument (code 1, ERROR_INVALID_VALUE)",
     "output_type": "error",
     "traceback": [
      "CUDA error: invalid argument (code 1, ERROR_INVALID_VALUE)\n",
      "\n",
      "Stacktrace:\n",
      "  [1] throw_api_error(res::CUDA.cudaError_enum)\n",
      "    @ CUDA C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\error.jl:89\n",
      "  [2] macro expansion\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\error.jl:97 [inlined]\n",
      "  [3] cuLaunchKernel(f::CuFunction, gridDimX::UInt32, gridDimY::UInt32, gridDimZ::UInt32, blockDimX::UInt32, blockDimY::UInt32, blockDimZ::UInt32, sharedMemBytes::Int64, hStream::CuStream, kernelParams::Vector{Ptr{Nothing}}, extra::Ptr{Nothing})\n",
      "    @ CUDA C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\utils\\call.jl:26\n",
      "  [4] #39\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:69 [inlined]\n",
      "  [5] macro expansion\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:33 [inlined]\n",
      "  [6] macro expansion\n",
      "    @ .\\none:0 [inlined]\n",
      "  [7] pack_arguments(::CUDA.var\"#39#40\"{Bool, Int64, CuStream, CuFunction, CuDim3, CuDim3}, ::CUDA.KernelState, ::CuDeviceVector{Int64, 1}, ::CuDeviceVector{Int64, 1}, ::CuDeviceVector{Int64, 1})\n",
      "    @ CUDA .\\none:0\n",
      "  [8] #launch#38\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:62 [inlined]\n",
      "  [9] #44\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:136 [inlined]\n",
      " [10] macro expansion\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:95 [inlined]\n",
      " [11] macro expansion\n",
      "    @ .\\none:0 [inlined]\n",
      " [12] convert_arguments\n",
      "    @ .\\none:0 [inlined]\n",
      " [13] #cudacall#43\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\lib\\cudadrv\\execution.jl:135 [inlined]\n",
      " [14] macro expansion\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\src\\compiler\\execution.jl:204 [inlined]\n",
      " [15] macro expansion\n",
      "    @ .\\none:0 [inlined]\n",
      " [16] #call#207\n",
      "    @ .\\none:0 [inlined]\n",
      " [17] #_#228\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\src\\compiler\\execution.jl:484 [inlined]\n",
      " [18] top-level scope\n",
      "    @ C:\\Users\\vikas\\.julia\\packages\\CUDA\\DfvRa\\src\\compiler\\execution.jl:104"
     ]
    }
   ],
   "source": [
    "# using threads\n",
    "\n",
    "a = CuArray(1:100_000)\n",
    "b = CuArray(1:100_000)\n",
    "c = similar(a)\n",
    "@cuda threads=length(a) vadd(c, a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "650d4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024"
     ]
    }
   ],
   "source": [
    "max_threads = CUDA.attribute(device(), CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)\n",
    "print(max_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09aff437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blocks_needed = cld(length(a),1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dac1445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000-element CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}:\n",
       "      2\n",
       "      4\n",
       "      6\n",
       "      8\n",
       "     10\n",
       "     12\n",
       "     14\n",
       "     16\n",
       "     18\n",
       "     20\n",
       "      ⋮\n",
       " 199984\n",
       " 199986\n",
       " 199988\n",
       " 199990\n",
       " 199992\n",
       " 199994\n",
       " 199996\n",
       " 199998\n",
       " 200000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function vadd(c, a, b)\n",
    "    i = threadIdx().x + (blockIdx().x - 1) * blockDim().x\n",
    "    if i <= length(a)\n",
    "        c[i] = a[i] + b[i]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "@cuda threads=1024 blocks=blocks_needed vadd(c, a, b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2eea1015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.HostKernel{typeof(vadd), Tuple{CuDeviceVector{Int64, 1}, CuDeviceVector{Int64, 1}, CuDeviceVector{Int64, 1}}}(vadd, CuFunction(Ptr{Nothing} @0x0000000091e5de20, CuModule(Ptr{Nothing} @0x00000000a017f590, CuContext(0x00000000918f14e0, instance d705e3f736760a58))), CUDA.KernelState(Ptr{Nothing} @0x0000000304000000))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Occupancy API - looks up how much actual hardware resources are needed \n",
    "# kernel programming\n",
    "kernel = @cuda launch=false vadd(c, a, b)\n",
    "kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6a38b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(blocks = 6, threads = 1024)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = CUDA.launch_configuration(kernel.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21b8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@show threads = min(length(a), config.threads)\n",
    "@show blocks = cld(length(a), threads)\n",
    "kernel(c, a, b; threads, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "729c79db",
   "metadata": {},
   "outputs": [
    {
     "ename": "CompositeException",
     "evalue": "On worker 2:\nArgumentError: Package CUDA not found in current path:\n- Run `import Pkg; Pkg.add(\"CUDA\")` to install the CUDA package.\n\nStacktrace:\n [1] require\n   @ .\\loading.jl:967\n [2] eval\n   @ .\\boot.jl:373\n [3] #103\n   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:274\n [4] run_work_thunk\n   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:63\n [5] run_work_thunk\n   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:72\n [6] #96\n   @ .\\task.jl:423\n\n...and 1 more exception.\n",
     "output_type": "error",
     "traceback": [
      "On worker 2:\n",
      "ArgumentError: Package CUDA not found in current path:\n",
      "- Run `import Pkg; Pkg.add(\"CUDA\")` to install the CUDA package.\n",
      "\n",
      "Stacktrace:\n",
      " [1] require\n",
      "   @ .\\loading.jl:967\n",
      " [2] eval\n",
      "   @ .\\boot.jl:373\n",
      " [3] #103\n",
      "   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:274\n",
      " [4] run_work_thunk\n",
      "   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:63\n",
      " [5] run_work_thunk\n",
      "   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\process_messages.jl:72\n",
      " [6] #96\n",
      "   @ .\\task.jl:423\n",
      "\n",
      "...and 1 more exception.\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] sync_end(c::Channel{Any})\n",
      "   @ Base .\\task.jl:381\n",
      " [2] macro expansion\n",
      "   @ .\\task.jl:400 [inlined]\n",
      " [3] remotecall_eval(m::Module, procs::Vector{Int64}, ex::Expr)\n",
      "   @ Distributed C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\macros.jl:219\n",
      " [4] top-level scope\n",
      "   @ C:\\Users\\vikas\\AppData\\Local\\Programs\\Julia-1.7.2\\share\\julia\\stdlib\\v1.7\\Distributed\\src\\macros.jl:203"
     ]
    }
   ],
   "source": [
    "using Distributed\n",
    "addprocs(length(devices()))\n",
    "@everywhere using CUDA\n",
    "\n",
    "# assign devices\n",
    "asyncmap((zip(workers(), devices()))) do (p, d)\n",
    "    remotecall_wait(p) do\n",
    "        @info \"Worker $p uses $d\"\n",
    "        device!(d)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bbfa4bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUDA.DeviceIterator() for 1 devices:\n",
       "0. NVIDIA GeForce MX150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21ee662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
