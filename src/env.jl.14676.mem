        - using ReinforcementLearning
        - using IntervalSets
        - using LinearAlgebra
        - using ControlSystems
        - using CUDA
        - 
        - include("./custom_control.jl")
        - include("./nodeconstructor.jl")
        - 
        - 
        - mutable struct SimEnv <: AbstractEnv
        -     nc
        -     sys_d
        -     action_space
        -     state_space
        -     done
        -     featurize
        -     prepare_action
        -     reward_function
        -     x0
        -     x
        -     t0
        -     t
        -     ts
        -     state
        -     maxsteps
        -     steps
        -     state_ids
        -     v_dc
        -     norm_array
        -     convert_state_to_cpu
        -     reward
        -     action
        -     action_ids
        - end
        - 
        0 function SimEnv(; maxsteps = 500, ts = 1/10_000, 
        -                   action_space = nothing, 
        -                   state_space = nothing, 
        -                   prepare_action = nothing, 
        -                   featurize = nothing, 
        -                   reward_function = nothing, 
        -                   CM = nothing, 
        -                   num_sources = nothing, 
        -                   num_loads = nothing, 
        -                   parameters = nothing, 
        -                   x0 = nothing, 
        -                   t0 = 0.0, 
        -                   state_ids = nothing, 
        -                   v_dc = nothing, 
        -                   norm_array = nothing, 
        -                   convert_state_to_cpu = true, 
        -                   use_gpu = false, 
        -                   reward = nothing, 
        -                   action = nothing, 
        -                   action_ids = nothing)
        -     
        -     if !(isnothing(CM) || isnothing(num_sources) || isnothing(num_loads))
        - 
        -         if isnothing(parameters)
        -             nc = NodeConstructor(num_sources = num_sources, num_loads = num_loads, CM = CM)
        -         else
        0             nc = NodeConstructor(num_sources = num_sources, num_loads = num_loads, CM = CM, parameters = parameters)
        -         end
        - 
        0         A, B, C, D = get_sys(nc)
        0         Ad = exp(A*ts)
        0         Bd = A \ (Ad - C) * B
        - 
        0         if use_gpu
        0             Ad = CuArray(A)
        0             Bd = CuArray(B)
        0             C = CuArray(C)
        -             if isa(D, Array)
        -                 D = CuArray(D)
        -             end
        -         end
        - 
       16         sys_d = HeteroStateSpace(Ad, Bd, C, D, Float64(ts))
        - 
        -     else
        -         # Construct standard env with 2 sources, 1 load
        -         println("INFO: Three phase electric power grid with 2 sources and 1 load is created! Parameters are drawn randomly! To change, please define parameters (see nodeconstructor)")
        -         CM = [ 0. 0. 1.
        -                0. 0. 2
        -               -1. -2. 0.]
        - 
        -         if isnothing(parameters)
        -             nc = NodeConstructor(num_sources = 2, num_loads = 1, CM = CM)
        -         else
        -             nc = NodeConstructor(num_sources = 2, num_loads = 1, CM = CM, parameters = parameters)
        -         end
        - 
        -         A, B, C, D = get_sys(nc)
        -         Ad = exp(A*ts)
        -         Bd = A \ (Ad - C) * B
        -         sys_d = HeteroStateSpace(Ad, Bd, C, D, Float64(ts))
        - 
        -     end
        - 
        0     if isnothing(action_space)
       96         action_space = Space([ -1.0..1.0 for i = 1:length(sys_d.B[1,:]) ], )
        -     end
        - 
        0     if isnothing(featurize)
        0         featurize = function(x0 = nothing, t0 = nothing; env = nothing) 
        -             if isnothing(env)
        -                 return x0
        -             else
        -                 return env.state
        -             end
        -         end
        -     end
        - 
        0     if isnothing(prepare_action)
        0         prepare_action = function(env) 
        0             env.action
        -         end
        -     end
        - 
        0     if isnothing(reward_function)
        -         reward_function = function(env) 
        -             return 0.0
        -         end
        -     end
        - 
        0     if isnothing(x0)
       80         x0 = [ 0.0 for i = 1:length(sys_d.A[1,:]) ]
        -     end
        - 
        0     x = x0
        -     t = t0
        - 
        -     state = featurize(x0,t0)
        - 
        0     if isnothing(state_space)
       80         state_space = Space([ -1.0..1.0 for i = 1:length(state) ], )
        -     end
        - 
        0     if use_gpu
        0         if isa(x0, Array)
        0             x0 = CuArray(x0)
        -         end
        0         if !(convert_state_to_cpu) && isa(state, Array)
        0             state = CuArray(state)
        -         end
        -     end
        - 
        0     if isnothing(state_ids)
        -         if isnothing(nc)
        -             state_ids = []
        -             println("WARNING: No state_ids array specified - observing states with DataHook not possible")
        -         else
        0             state_ids = get_state_ids(nc)
        -         end
        -     end
        - 
        0     if isnothing(action_ids)
        -         if isnothing(nc)
        -             action_ids = []
        -             println("WARNING: No state_ids array specified - observing states with DataHook not possible")
        -         else
        0             action_ids = get_action_ids(nc)
        -         end
        -     end
        -     # TODO: take vdc per source from the nc.parameters[] something like:
        -     # v_dc = [env.nc.parameters["sources"][n]["vdc"] for n = 1:env.nc.num_sources]
        0     if isnothing(v_dc)
      144         println("INFO: v_dc = 350V will get applied to all actions")
        0         v_dc = 350 * ones(length(action_space))
        -     elseif isa(v_dc, Number)
        -         println("INFO: v_dc = $(v_dc)V will get applied to all actions")
        -         v_dc = v_dc * ones(length(action_space))
        -     end
        -     
        -     #TODO: norm_array from parameters Dict
        0     if isnothing(norm_array)
        -         if isnothing(nc)
        -             println("INFO: norm_array set to ones - if neccessary please define norm_array in env initialization")
        -             norm_array = ones(length(sys_d.A[1,:]))
        -         else
      448             println("INFO: Generating standard norm_array from nodeconstructor")
        0             states = get_state_ids(nc)
       48             norm_array = []
      144             println("WARNING: limits set to fixed value - define in nc.parameters")
       32             for state_name in states
        0                 if startswith(state_name, "i")
        -                     #push!(norm_array, limits["i_lim"])
       80                     push!(norm_array, 20.0)
        0                 elseif startswith(state_name, "u")
        -                     #push!(norm_array, limits["v_lim"])
        0                     push!(norm_array, 600.0)
        -                 end
      224             end
        -         end
        -     end
        - 
        0     if isnothing(reward)
        -         reward = 0.0
        -     end
        - 
        0     if isnothing(action)
        0         action = zeros(length(action_space))
        -     end
        - 
      272     SimEnv(nc, sys_d, action_space, state_space, false, featurize, prepare_action, reward_function, x0, x, t0, t, ts, state, maxsteps, 0, state_ids, v_dc, norm_array, convert_state_to_cpu, reward, action, action_ids)
        - end
        - 
        - RLBase.action_space(env::SimEnv) = env.action_space
        - RLBase.state_space(env::SimEnv) = env.state_space
        - RLBase.reward(env::SimEnv) =  env.reward 
        - 
        - 
        - RLBase.is_terminated(env::SimEnv) = env.done
        - RLBase.state(env::SimEnv) = env.state
        - 
        - function RLBase.reset!(env::SimEnv)
        0     env.state = env.convert_state_to_cpu ? Array(env.featurize(env.x0, env.t0)) : env.featurize(env.x0, env.t0)
        0     env.x = env.x0
        0     env.t = env.t0
        0     env.steps = 0
        0     env.reward = 0.0
        0     env.done = false
        0     nothing
        - end
        - 
        - function (env::SimEnv)(action)
   113920     env.steps += 1
        -     # i_1, v_1 , i_L = 
        -     # why tt??
  4608000     tt = [env.t, env.t + env.ts]
        - 
   768000     env.t = tt[2]
        - 
        0     env.action = action
        - 
        0     env.action = env.action .* env.v_dc
        - 
        0     env.action = env.prepare_action(env)
        -     
        0     if env.sys_d.A isa CuArray && !(env.action isa CuArray)
        0         if env.action isa Array
        0             env.action = CuArray(env.action)
        -         else
        0             env.action = CuArray([env.action])
        -         end
        -     end
        0     u = [env.action env.action]
        - 
  1536000     xout_d = custom_lsim(env.sys_d, u, tt, x0=env.x)
        -     #xout_d = [env.x env.x]
        - 
   768000     env.x = xout_d[:,2]
        -     #env.x = xout_d'[2,:]
        0     if env.convert_state_to_cpu
  1536000         env.state = Array(xout_d)'[2,:] ./ env.norm_array
        -     else
        0         env.state = xout_d'[2,:] ./ env.norm_array
        -     end
        - 
   767984     env.state = env.featurize(; env = env)
        - 
        -     # reward
        -     # loss_error = 1e-1
        -     # hardcoded values - change later
        -     # use functions outside this reward function - normalised
        -     # P_load = (env.norm_array[end] * env.state[end])^2 / 14
        -     # push!(PLoad, P_load)
        -     # P_diff = -abs(P_required - P_load)   
        - 
        -     # env.reward = -sqrt((P_source - (P_R + P_load + loss_error))^2)
        -     # Power constraint
        0     env.reward = env.reward_function(env)
        - 
        0     env.done = env.steps >= env.maxsteps
        - end
